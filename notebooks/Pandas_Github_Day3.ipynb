{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Data Analysis with Python: Overview of Pandas\n",
    "Author: Fermín Huarte Larrañaga\n",
    "Created: 2015\n",
    "Version: 2.0\n",
    "Date: June 2017\n",
    "\n",
    "## Bibliography\n",
    "This IPython Notebook is based almost completely on:\n",
    "\n",
    "- \"_Python for Data Analysis_\" by Wes McKinney, Ed. O'Reilly, 2012.\n",
    "\n",
    "Online resources:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Python: Overview of Pandas\n",
    "The aim of this session is to have a first experience with tools that should allow you to manipulate, process, clean, and crunch data using Python. By \"data\" we are referring to _structured data_ such as:\n",
    "- multidimensional arrays\n",
    "- tabular or spreadsheet-like data\n",
    "- time series (no necessarily evenly spaced!)\n",
    "- multiple data related by key columns\n",
    "##Why Python when analyzing data?\n",
    "There a considerable amount of alternatives when it comes to analyzing large sets of data such as R, MATLAB, SAS, Stata, and others. Efficient as they may be, they are often restricted to a small area of application. The versatility of Python and the growing comunity of Python users in the scientific domain has provided an remarkable improvement in its library support during the recent years, becoming a strong competitor for data manipulation tasks. Added to Python's strength as a general purpose programming language it becomes an excellent choice as a single platform to develop a data analysis application. \n",
    "\n",
    "Essential libraries we will be using:\n",
    "- NumPy\n",
    "- pandas (new!)\n",
    "- matplotlib\n",
    "- IPython\n",
    "- SciPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wetting our appetite\n",
    "Before learning the basics of data analysis with pandas we will emulate author of the pandas module and start by running a not so simple. Do not intend to fully understand the instructions given in the next cells. They will be introduced along the session. Relax, try to understand its logic, and enjoy! ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from a URL shortenning service\n",
    "\n",
    "In 2011, the URL shortenning service named bit.ly partnered with the US governement website `usa.gov` to provide a food of anonymous data gathered from users who shorten links ending with `.gov` or `.mil`. This data (updated daily with hourly snapshots) can be downloaded as text files. Each line in the hourly snapshot data file contains a JSON (_JavaScript Object Notation_) form. \n",
    "\n",
    "Will work with this data using first standard built-in Python, then the `collections` module and finally, pandas.\n",
    "\n",
    "#### Standard Python\n",
    "\n",
    "The following lines will open such file and display its contents. Please, download [this data file](https://www.dropbox.com/s/5rtbbpu241lgv97/usagov_bitly_data2012-03-16-1331923249.txt?dl=0) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file ='usagov_bitly_data2012-03-16-1331923249.txt'\n",
    "file = open(data_file)\n",
    "file.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead, of opening it as a simple text file, we will load the lines in the JSON file into a dictionary object. Let us read de data set using JavaScript Object Notation `json` module (we will not cover this topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data_file = 'usagov_bitly_data2012-03-16-1331923249.txt'\n",
    "records = [json.loads(line) for line in open(data_file)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the `json` module now variable `records` is a list of dictionaries, imported from the JSON form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variable records is {} and its elements are {}.\".format(type(records),type(records[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the first element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, this is a typical `dictionary` structure with keys and values. Find out the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out the value for the key `'tz'` in this first record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case (and we were not supposed to know this) `'tz'` stands for time zone. Suppose we are interested in identifying the most commonly found time zones in the set of data we just imported. Surely, each one of you will find a different way to work around it. First, we want to obtain a list of all time zones found in the list, name the list as `list_of_timezones`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of `list_of_timezones` and, for instance its first ten elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to think of an algorithm to count the occurences of the different timezones (including the blank field `' '`). _Hint: You might want to use a dictionary to store the occurence_ (If you can't solve it, follow [this link](https://www.dropbox.com/s/cx5wx271cg3wubz/pandas1.py?dl=0) for a possible solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How often does 'America/Sao_Paulo' appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- How many different timezones are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find out the top 10 time zones ([sample code](https://www.dropbox.com/s/6j9xhptguj9ooaq/pandas2.py?dl=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Collections module\n",
    "\n",
    "The Python standard library provides the `collections` [module](https://docs.python.org/3/library/collections.html \"collections module documentation page\") that contains the `collections.Counter` class. This does the job that we just made but in a nicer way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "print(\"First counter is of \", type(counter))\n",
    "counter = collections.Counter(counter) #generate an instance to the Counter class using our counter variable\n",
    "print(\"Now counter is of \", type(counter))\n",
    "#The Counter class has new useful functionalities\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pandas alternative\n",
    "Now, let us do the same work using **pandas**. The main pandas data structure is the `DataFrame`. It can be seen as a representation of a table or spreadsheet of data. First, we will create the DataFrame from the original data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "myframe = DataFrame(records)\n",
    "myframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`myframe` is now a DataFrame, a class introduced by pandas to efficiently work with structured data. Check the type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(myframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` object is composed of `Series` (another pandas object), They can be seen as the _columns of a spreadsheet_. For instance, `myframe['tz']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(myframe['tz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the time zones (`'tz'`) in the first ten records of `myframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Series` object has a useful method: `value_counts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tz_counter = myframe['tz'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one line of code, all the timezones are grouped and accounted for. Check the result and get the top 5 time zones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much few lines of work, right? As we have said repeatedly, there is no need to reinvent the wheel. Probably someone out there solved your problem before you ran into it and, unless you are really really good, that solution is probably better than yours! ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we might want to plot the data using the matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line configures matplotlib to show figures embedded in the notebook, \n",
    "# instead of opening a new window for each figure.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can call matplotlib directly without calling the module explicitly. We will make an histogramatic plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counter[:10].plot(kind='barh', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is kind of odd to realize that the second most popular timezone has a _blank_ label. The `DataFrame` object of pandas has a `fillna` function that can replace missing (NA) values or empty strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we generate new Series from a column of myframe, when a value is 'NaN' insert the word 'Missing'\n",
    "clean_tz = myframe['tz'].fillna('Missing')\n",
    "#In this new Series replace EMPTY VALUES with the word 'Unknown'. Try to understand BOOLEAN INDEXING\n",
    "clean_tz[clean_tz == ''] = 'Unknown'\n",
    "#Use the method VALUE_COUNTS to generate a new Series containing time zones and occurrences\n",
    "tz_counter = clean_tz.value_counts()\n",
    "#Finally, plot the top ten values\n",
    "tz_counter[:10].plot(kind='barh', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's complicate the example a bit more. The `'a'` field in the datasheet contains information on the browser used to perform the URL shortening. For example, check the content of the `'a'` field in the first record of `myframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a `Series` from the datasheet containing all the browser data: try to understand the following line. A good strategy might be to work it out by pieces:\n",
    "```python\n",
    "myframe.a\n",
    "myframe.a.dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = Series([x.split()[0] for x in myframe.a.dropna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with the time zones, we can use the `value_counts` method on the browser `Series` to see the most common browsers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decompose the top time zones into people using Windows and not using Windows. This piece of code requires some more knowledge of pandas, skip the details for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cframe = myframe[myframe.a.notnull()]\n",
    "os = np.where(cframe['a'].str.contains('Windows'),'Windows','Not Windows')\n",
    "tz_and_os = cframe.groupby(['tz',os])\n",
    "agg_counter = tz_and_os.size().unstack().fillna(0)\n",
    "agg_counter[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the top overall time zones. To do so, we construct an indirect index array from the row counts in `agg_counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use to sort in ascending order\n",
    "indexer = agg_counter.sum(1).argsort()\n",
    "indexer[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `take` to select the rows in that order and then slice off the last 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_subset = agg_counter.take(indexer)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset.plot(kind='barh', stacked='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same plot, but percentages instead of absolute numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_normalized = count_subset.div(count_subset.sum(1), axis=0)\n",
    "subset_normalized.plot(kind='barh', stacked='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this example. We will go through the basics of pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## `DataFrame` and `Series`\n",
    "\n",
    "The two basic Data Structures introduced by pandas are `DataFrame` and `Series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Series`\n",
    "\n",
    "A `Series` is a one-dimensional array-like object containing an array of data (any NumPy data type is fine) and associated array of _data labels_, called _index_. The simplest Series one can think of would be formed only by an array of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = Series([-4, 7, 11, 13, -22])\n",
    "o1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the representation of the Series shows the index on the left and the values on the right. No index was specified when the Series was created and a default one has been assigned: integer number from 0 to N-1 (N would be de length of the data array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we need to specify the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o2 = Series([7, 0.2, 11.3, -5], index=['d','e','a','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike NumPy arrays, we can use values in the index when selecting single values from a set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o2['e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is also equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values correspondong to two indices (notice double square brackets!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2[['z','d']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy array operations, such as masking using a boolean array, scalar broadcasting, or applying mathematical functions, preserve the index-value link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2[o2 > 0] #filter positive elements in o2, the indices are conserved. Compare with the same operation in a NumPy array!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2*np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas `Series` have also been described as a fixed.length, ordered _dictionary_, since it actually maps index values to data values. Many functions that expect a `dict` can be used with `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'z' in o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Python dictionary can be used to create a pandas Series, here is a list of the top 5 most populated cities (2015) according to [Wikipedia](http://en.wikipedia.org/wiki/List_of_cities_proper_by_population):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = {'Shanghai': 24150000, 'Karachi': 23500000, 'Beijing': 21516000, 'Tianjin': 14722000, 'Istanbul': 14377000}\n",
    "print (\"pop_data is of type \",type(pop_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = Series(pop_data)\n",
    "print(\"ser1 is of type \",type(ser1))\n",
    "print(\"Indices of the Series are: \",ser1.index)\n",
    "print(\"Values of the Series are: \",ser1.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you just checked, when passing the dictionary the resulting Series uses the `dict` keys as indices and sorts the values corresponding to the index.\n",
    "\n",
    "In the next case we create a `Series` from a dictionary but selecting the indices we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Karachi', 'Istanbul', 'Beijing', 'Moscow']\n",
    "ser2 = Series(pop_data, index=cities)\n",
    "ser2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values found in `pop_data` have been placed in the appropiate locations. No data was found for `'Moscow'` and value `NaN` is assigned. This is used in pandas to mark missing or not available (NA) values. In order to detect missing data in pandas, one should use the `isnull` and `notnull` (both present as functions and Series methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(ser2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important feature of Series to be highlighted here is that Series are automatically aligned when performing arithmetic operations. It doesn't make much sense to add the population data but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 + ser2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign names to both the Series object and its index using the `name` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1.name = 'population'\n",
    "ser1.index.name = 'city'\n",
    "ser1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame`\n",
    "\n",
    "The `DataFrame` object represents a tabular, spreadsheet-like data structure containing an ordered collection of columns, each of which can be a different value `type`. The `DataFrame` has both a row and column index and it can be seen as a `dictionary` of `Series`. Under the hood, the data is stored as one or more 2D blocks rather than a list, dict, or some other collection of 1D arrays. See the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'city': ['Madrid', 'Madrid','Madrid','Barcelona','Barcelona','Sevilla','Sevilla','Girona','Girona','Girona'],\n",
    "       'year': ['2002', '2006', '2010', '2006', '2010', '2002', '2010', '2002', '2006', '2010'],\n",
    "       'pop': [5478405, 5953604, 6373532, 5221848, 5488633, 1732697, 1902956, 568690, 668911, 741841]}\n",
    "pop_frame = DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `DataFrame` has automatically assigned indices and the columns are sorted. This order can be altered if we specify a sequence of colums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(data, columns=['year','city','pop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should keep in mind that indices in the DataFrame are `Index objects`, they have attributes (such as name as we will see) and are immutable.\n",
    "\n",
    "What will happen if we pass a column that is not contained in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame2 = DataFrame(data, columns=['year','city','pop','births'])\n",
    "pop_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column in a `DataFrame` can be retrieved as a Series in two ways:\n",
    "\n",
    "- using dict-like notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame2['city']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using the `DataFrame` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame2.city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can be modified by assignment. Let's get rid of those NA values in the births column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame2['births'] = 100000\n",
    "pop_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When assigning lists or arrays to a column, the values' length must match the length of the DataFrame. If we assign a Series it will be instead conformed exactly to the DataFrame's index, inserting missing values in any holes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "birth_series = Series([100000, 15000, 98000], index=[0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame2['births'] = birth_series\n",
    "pop_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a column that doesn't exist will result in creating a new column. Columns can be deleted using the `del` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame2['Catalunya'] = ((pop_frame2.city == 'Barcelona') | (pop_frame2.city == 'Girona'))\n",
    "pop_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pop_frame2['Catalunya']\n",
    "pop_frame2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the `DataFrame` can be built from a nested `dict` of `dicts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = {'Madrid': {'2002': 5478405, '2006': 5953604, '2010': 6373532}, \n",
    "            'Barcelona': {'2006': 5221848, '2010': 5488633}, 'Sevilla': {'2002': 1732697, '2010': 1902956}, \n",
    "            'Girona': {'2002': 568690, '2006': 668911, '2010': 741841}}\n",
    "pop_frame3 = DataFrame(pop_data)\n",
    "pop_frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outer dict keys act as the columns and the inner keys as the unioned row indices. Possible data inputs to construct a `DataFrame`:\n",
    "\n",
    "- 2D NumPy array\n",
    "- dict of arrays, lists, or tuples\n",
    "- dict of Series\n",
    "- dict of dicts\n",
    "- list of dicts or Series\n",
    "- List of lists or tuples\n",
    "- DataFrames\n",
    "- NumPy masked array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `Series`, the `index` and `columns` in a `DataFrame` have `name` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame3.columns.name = 'city'; pop_frame3.index.name = 'year'\n",
    "pop_frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Similarly, the `values` attribute returns de data contained in the DataFrame as a 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functionality\n",
    "\n",
    "We will not cover all the possible operations using Pandas and the related data structures. We will try to cover some of the basics.\n",
    "\n",
    "### Reindexing\n",
    "A critical method in pandas is `reindex`. This implies creating a new object with the data of a given structure but _conformed_ to a new index. For instance:\n",
    "\n",
    "1. Extract the column of pop_frame3 belonging to `Barcelona`\n",
    "2. Check the type of the column, it should be a `Series`\n",
    "3. Find out the indices of the `Barcelona Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `reindex` on the `Barcelona Series` to rearrange the data to a new index [2010, 2008, 2006, 2004, 2002], following this example:\n",
    "```python\n",
    "obj = Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\n",
    "obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reindex` method can be combined with the `fill_value=` option in the non existing values:\n",
    "```python\n",
    "obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'], fill_value=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does'nt make much sense in this case to estimate the non-existing values as zeros. For ordered data such as time series, we can use interpolation or foward/backward filling.\n",
    "\n",
    "___\n",
    "In the case of DataFrames, `reindex` can alter either (row) index, column or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverting the row indices and adding some more years\n",
    "years = ['2010', '2008', '2006', '2004', '2002']\n",
    "pop_frame4 = pop_frame3.reindex(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead we want to reindex the columns, we need to use the `columns` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Madrid', 'Sevilla','Barcelona', 'Girona']\n",
    "pop_frame4 = pop_frame4.reindex(columns=cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_frame4 = pop_frame3.reindex(index = years, columns = cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reindex` [function arguments](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping entries from an axis\n",
    "From the Barcelona population Series let's get rid of years 2002 and 2008:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_bcn2.drop(['2002', '2008'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the object was not modified.\n",
    "\n",
    "In DataFrame, index values can be deleted from both axes. Use the IPython help to find out the use of `drop` and get rid of all the data related to Madrid and year 2002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, selection, and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Series\n",
    "Indexing in `Series` works similarly to NumPy array indexing. The main difference is that we can actually use the Serie's index instead of integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_bcn2.index.name = 'year'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population in Barcelona in year 2006?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean indexing, non-zero data in Barcelona?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important__: Slicing with labels behaves differently than normal Python slicing **the endpoint is inclusive**! Give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_bcn2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_bcn2['2002':'2006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
